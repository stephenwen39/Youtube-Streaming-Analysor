# Youtube Streaming Analysor

-------------------------------

This is a project for analysis of YouTuber/vtuber streaming data, focusing on chat/user pairs data analysis. If you are interested in the evolution, see the Change Log(æ›´æ–°æ™‚é–“è»¸) of this side-project below.

This data pipeline is currently migrated to the Google Cloud platform. Please see the simplified architecture diagram below for the system structure.

ğŸ“ˆ [Dashboard](https://lookerstudio.google.com/reporting/d0c687bd-2e96-4fac-ac9a-f1d5844fe8d8) 

ğŸ“ [Article: System Architecture and Challenges](https://stephendatavisualization.substack.com/p/building-a-lambda-architecture-gcp)

<p align="center"><img width="90%" src="plots/pipeline and dashboard_3.png" /></p>

-------------------------------

æ½›åœ¨å•é¡Œé›†(Potential issues list):

1. ç”±æ–¼ batch update çš„ç³»çµ±é™åˆ¶ï¼Œå¦‚æœç›´æ’­å½±ç‰‡è¢«ä¸‹æ¶å‰‡åªèƒ½æŠ“åˆ°å³æ™‚è§€çœ‹æ•¸ï¼Œå…¶ä»–è³‡æ–™ç„¡æ³•æŠ“å–(Due to the system limitations of batch updates, if the live video is taken down, only the real-time view count can be captured, and other data cannot be retrieved.)

-------------------------------

Change Log æ›´æ–°æ™‚é–“è»¸

2024.07.14: æ›´æ–° Looker Studio è¦–è¦ºæ•ˆæœï¼ŒåŠ å…¥ online è§€çœ¾æŠ˜ç·šåœ–ã€‚

2024.07.14: Update ploys in Looker Studio: add the viewer's count line chart.

2024.07.05: ç”±æ–¼ Youtube Data API çš„é…é¡é™åˆ¶éä½ï¼Œæ”¹ç”¨ç´”çˆ¬èŸ²çˆ¬å–ç›´æ’­ç‹€æ…‹èˆ‡è§€çœ‹äººæ•¸ã€‚

2024.07.05: Use Python crawler to get the streaming status and the viewers instead of Youtube Data API, because the quota of it is limited.

2024.06.30: åŸºæ–¼ Youtube Data API å¢åŠ ä¸€å€‹æ–°è³‡æ–™æº "ç•¶ä¸‹è§€çœ¾æ•¸é‡"ï¼Œä¸¦ä¸”åŸºæ–¼æ­¤è³‡æ–™æºå»ºæ§‹ä¸€å€‹æ–°çš„è³‡æ–™ç®¡é“ã€‚é€™å€‹ä¸²æµè³‡æ–™ç®¡é“ç”± cloud function èˆ‡ pubsub çµ„æˆï¼Œæä¾›ç›´æ’­ç•¶ä¸‹çš„è§€çœ¾æ•¸é‡(è³‡æ–™é¡†ç²’åº¦é”åˆ°æ¯åˆ†é˜)ã€‚

2024.06.30: Add a new data source "viewers count" based-on YouTube Data API, and construct a new pipeline with it. This pipeline is a streaming pipeline consisting of cloud function and pub/sub(Apache Kafka), providing streaming live viewers count per minute.

2024.05.19: å°‡ JOIN æ“ä½œæ¬é·åˆ° Bigquery é€²è¡Œï¼Œæé«˜ 30 å€çš„å„€è¡¨æ¿è¼‰å…¥æ•ˆç‡ã€‚(60ç§’ -> 2ç§’)

2024.05.19: Switching the JOIN operation to BigQuery increased the dashboard loading efficiency by 30 times. (60s -> 2s)

2024.05.02: æ§‹æ€åŠ å…¥ youtube live stream online viewers numbers çš„åŠŸèƒ½ (ä½¿ç”¨ API: https://developers.google.com/youtube/v3/getting-started?hl=zh-tw#quota)ã€‚

2024.05.02: Conceptualize a youtube live stream online viewers numbers feature. (API: https://developers.google.com/youtube/v3/getting-started?hl=zh-tw#quota)ã€‚

2024.05.01: æ§‹æ€ Looker Studio (LS) åŠ é€Ÿæ–¹æ¡ˆï¼Œä¸»è¦æ–¹å‘æœƒæ¨æ£„ç›®å‰ LS ä¸­å¤§é‡çš„ tables JOIN è¡Œç‚ºï¼ŒLS çš„å¤§é‡ tables JOIN å·²ç¶“åœ¨ç¶²è·¯ä¸Šè¢«å…¬èªæ˜¯å½±éŸ¿å„€è¡¨æ¿è¼‰å…¥é€Ÿåº¦çš„é—œéµä¹‹ä¸€ã€‚å› æ­¤ç›®å‰æœƒé€æ­¥å°‡ LS ä¸­çš„ JOIN è¡Œç‚ºæå‰åˆ° BQ è™•ç†ã€‚

2024.05.01: Conceptualize a Looker Studio (LS) processing speed acceleration plan, primarily focusing on abandoning the extensive use of tables JOIN currently in LS. The substantial tables JOIN in LS has been widely recognized on the internet as one of the key factors affecting dashboard loading speed, the JOIN operation will pre-process in Bigquery instead.

2024.03.02: åŠ å…¥ DBT trigger BQ pipeline æ¸¬è©¦ï¼ŒæˆåŠŸï¼Œå¾…éƒ¨ç½²åˆ° prod ä¸Šã€‚

2024.03.02: Finish DBT trigger BQ pipeline test, ready to implement on prod inv.

2023.07.20: å°‡æ•´å€‹æµç¨‹æ¬é·åˆ°GCPä¸Šï¼Œç”¨cloud function / Bigquery / Looker studioå®Œæˆä¸€ç³»åˆ—çš„è³‡æ–™ç®¡é“èˆ‡å„€è¡¨æ¿

2023.07.20: move the project to GCP, using Cloud Function, Bigquery, Looker Studio to build a pipeline and dashboard.

2022.12.23: ä¿®å¾©live_info.pyä½¿ç”¨è€…è¨ˆæ•¸ä¸Šçš„éŒ¯èª¤

2022.12.23: Fix the bug of live_info.py.

2022.12.22: æ–°å¢å–®å ´ç›´æ’­çš„ä½¿ç”¨è€…çµ±è¨ˆåŠŸèƒ½

2022.12.22: Upload the user statistics function for a single live broadcast.

2022.12.21: ä¿®å¾©get_streams_from_channel.pyä¸­ï¼Œlimitå°æ–¼å°šæœªé–‹å§‹çš„ç›´æ’­æ•¸æœƒå›å‚³éŒ¯èª¤urlæ•¸é‡çš„å•é¡Œï¼ˆä½†æ˜¯ç›®å‰æ˜¯ä½¿ç”¨æ•ˆç‡ä½çš„æ–¹æ³•ï¼Œä¹‹å¾Œå¯èƒ½è¦ç›´æ¥å‹•source codeä¾†ç¹¼çºŒæ”¹å–„ï¼‰

2022.12.21: Fix the problem of get_streams_from_channel.py, now the return urls list is right.

2022.12.19: ä»¥get_streams_from_channel.pyé”æˆé »é“ç›´æ’­çˆ¬èŸ²è‡ªå‹•åŒ–ï¼Œè¼¸å…¥é »é“é€£çµèˆ‡æƒ³çˆ¬å–çš„ç›´æ’­urlæ•¸é‡ï¼Œå³å¯å–å¾—æƒ³è¦çš„çµæœï¼Œç‰¹åˆ¥çš„æ˜¯æˆ‘ä½¿ç”¨ä¸‹åˆ—å¥—ä»¶ï¼Œä¸¦ä¸”å°‡å…¶ä¿®æ”¹ä»¥ç¬¦åˆæˆ‘çš„ä½¿ç”¨éœ€æ±‚

2022.12.19: Use get_streams_from_channel.py to automatically crawl the URL of a particular channel.

reference:https://github.com/dermasmid/scrapetube

2022.12.18: ä¿®æ­£åç¨±é–‹é ­æœ‰'()'è€…å°è‡´çš„èº«ä»½è­˜åˆ¥éŒ¯èª¤èˆ‡å§“ååˆ‡å‰²éŒ¯èª¤

2022.12.18: Fix the problem of the starting of the user id include '()'.

2022.12.17: æ–°å¢live_info.pyï¼Œå¯ä»¥ä¾æ“šliveæ™‚é–“ï¼ˆåˆ†é˜æ•¸ï¼‰è¨ˆç®—ä½¿ç”¨è€…ç•™è¨€é‡ã€ä½¿ç”¨è€…listã€ç•™è¨€listï¼Œå¦‚æœè©²æ™‚é–“æ²’æœ‰ç•™è¨€ï¼Œæœƒé¡¯ç¤º0å€‹ä½¿ç”¨è€…ã€ä»¥åŠå…©å€‹ç©ºç™½list

2022.12.17: Upload live_info.py, it based on minutes to summarized user/messages information.

2022.12.15: æ–°å¢user_analysor.pyæª”æ¡ˆï¼ŒåŠŸèƒ½æ˜¯å½™æ•´è©²ç›´æ’­ä¸­çš„æ‰€æœ‰ä½¿ç”¨è€…è³‡è¨Šï¼Œå¦å¤–ä¹‹å‰æ²’è€ƒé‡çš„Verifiedèº«ä»½ä¹Ÿåœ¨é€™æ¬¡æ›´æ–°ä¸­ä¿®æ­£å®Œæˆ

2022.12.15: Upload user_analysor.py, I use it to summarize user information in a streaming live, also I fix the 'Verified' identity problem. In the original version, I didn't consider the 'Verified' identity.

2022.11.22: æ›´æ”¹data pipelineï¼Œå¾ç›´æ¥åŒ¯å…¥dfæ”¹æˆå…ˆä»¥listæ‰¿æ¥å†çµ±ä¸€åŒ¯å…¥dfï¼Œæ­¤èˆ‰æ”¹å–„11/21ç‰ˆæœ¬è¿‘åå€çš„æ•ˆèƒ½ï¼ˆä½¿ç”¨åŒä¸€æ”¯ç›´æ’­å½±ç‰‡æ¸¬è©¦ï¼Œç¸½èŠ±è²»CPU timeå¾366ä¸‹é™åˆ°30ï¼‰ã€‚å°æ¯”Pre_processor.pyï¼Œæ­¤ç‰ˆæœ¬å¢é€²äº†40%å·¦å³çš„æ•ˆèƒ½ï¼Œä¸¦ä¸”å…·å‚™æ›´å¤šæ¬„ä½ï¼Œèƒ½é”æˆæ›´å¤šç›®çš„

2022.11.22: Fix the data pipeline, use list to store raw data instead of using df directly, and improve 10 times of efficiency compare with the version build in 11.21. This version is 40% more efficiency compare with Pre_processor.py.

2022.11.21: å®Œæˆ2.0ç‰ˆæœ¬çš„åˆæ­¥å…§å®¹ï¼Œä»¥Pre_processor_2.0.pyç‚ºæª”æ¡ˆåç¨±ï¼Œæ¨æ£„listèˆ‡dictçš„è³‡æ–™è£è¼‰æ–¹å¼ï¼Œæ¸…æ´—å¾Œçš„è³‡æ–™å…¨é¢æ”¹ç”¨pandasçš„dataframeè£è¼‰

2022.11.21: Finish the 2.0 version, use dataframe to store the data

2022.11.19: è¨ˆåŠƒç”¨pandasæŠŠpipelineé‡æ§‹æˆæ›´æœ‰æ•ˆç‡çš„è™•ç†æ–¹å¼

2022.11.19: TO DO: Use pandas package to refactor the data pipeline.

2022.10.16: 10.15æå‡ºçš„å•é¡Œå·²ä¿®å¾©

2022.10.16: Update: problem mention at 10.15 solved.

2022.10.15: ç›®å‰æœƒæœ‰ä¸€å€‹å•é¡Œï¼šå¦‚æœä½¿ç”¨è€…åç¨±ä¸­æœ‰New, Memberç­‰è©å½™æœƒé€ æˆåˆ¤æ–·éŒ¯èª¤ï¼Œä¿®æ”¹ä¸­

2022.10.15: Currently problem: once there is "New" or "Member" in the user ID, error occour, fixing.

2020: è£½ä½œæœ€æ—©ç‰ˆæœ¬çš„Pre_processor.py

2020: Upload Pre_processor.py

-----------------------------------------
åœ–é›†:

The following four plots are visualization examples(based on user's messages):
<p align="center"><img width="65%" src="plots/compare_three_live.png" /></p>

<p align="center"><img width="65%" src="plots/compare_three_live_2.png" /></p>

<p align="center"><img width="80%" src="plots/compare_seven_live_chat_2.png" /></p>

<p align="center"><img width="65%" src="plots/description.png" /></p>

reference:
https://github.com/xenova/chat-downloader
